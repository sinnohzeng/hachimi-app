// ---
// ğŸ“˜ æ–‡ä»¶è¯´æ˜ï¼š
// LLM Provider â€” AI åŠŸèƒ½å¯ç”¨æ€§çŠ¶æ€æœºã€æ¨¡å‹ä¸‹è½½è¿›åº¦ã€æœåŠ¡å®ä¾‹ç®¡ç†ã€‚
//
// ğŸ“‹ Provider Graph:
// - aiFeatureEnabledProviderï¼šAI åŠŸèƒ½å¼€å…³ï¼ˆSharedPreferences æŒä¹…åŒ–ï¼‰
// - llmAvailabilityProviderï¼šLLM å¯ç”¨æ€§çŠ¶æ€æœº
// - llmServiceProviderï¼šLLM æ¨ç†æœåŠ¡å®ä¾‹
// - modelDownloadProgressProviderï¼šæ¨¡å‹ä¸‹è½½è¿›åº¦
//
// ğŸ•’ åˆ›å»ºæ—¶é—´ï¼š2026-02-19
// ---

import 'dart:async';

import 'package:background_downloader/background_downloader.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter_riverpod/legacy.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'package:hachimi_app/core/constants/llm_constants.dart';
import 'package:hachimi_app/services/llm_service.dart';
import 'package:hachimi_app/services/model_manager_service.dart';
import 'package:hachimi_app/services/local_database_service.dart';
import 'package:hachimi_app/services/diary_service.dart';
import 'package:hachimi_app/services/chat_service.dart';

// â”€â”€â”€ Service Providers â”€â”€â”€

final modelManagerProvider =
    Provider<ModelManagerService>((ref) => ModelManagerService());

final localDatabaseProvider =
    Provider<LocalDatabaseService>((ref) => LocalDatabaseService());

final llmServiceInstanceProvider = Provider<LlmService>((ref) => LlmService());

final diaryServiceProvider = Provider<DiaryService>((ref) {
  return DiaryService(
    llmService: ref.watch(llmServiceInstanceProvider),
    dbService: ref.watch(localDatabaseProvider),
  );
});

final chatServiceProvider = Provider<ChatService>((ref) {
  return ChatService(
    llmService: ref.watch(llmServiceInstanceProvider),
    dbService: ref.watch(localDatabaseProvider),
  );
});

// â”€â”€â”€ AI Feature Toggle â”€â”€â”€

/// AI åŠŸèƒ½æ€»å¼€å…³ â€” æŒä¹…åŒ–åˆ° SharedPreferencesã€‚
class AiFeatureNotifier extends StateNotifier<bool> {
  AiFeatureNotifier() : super(false) {
    _load();
  }

  Future<void> _load() async {
    final prefs = await SharedPreferences.getInstance();
    state = prefs.getBool(LlmConstants.prefAiEnabled) ?? false;
  }

  Future<void> toggle() async {
    state = !state;
    final prefs = await SharedPreferences.getInstance();
    await prefs.setBool(LlmConstants.prefAiEnabled, state);
  }

  Future<void> setEnabled(bool value) async {
    state = value;
    final prefs = await SharedPreferences.getInstance();
    await prefs.setBool(LlmConstants.prefAiEnabled, value);
  }
}

final aiFeatureEnabledProvider =
    StateNotifierProvider<AiFeatureNotifier, bool>(
  (ref) => AiFeatureNotifier(),
);

// â”€â”€â”€ LLM Availability â”€â”€â”€

/// LLM å¯ç”¨æ€§çŠ¶æ€ã€‚
enum LlmAvailability {
  featureDisabled,
  modelNotDownloaded,
  modelLoading,
  ready,
  error,
}

/// LLM å¯ç”¨æ€§çŠ¶æ€æœºã€‚
class LlmAvailabilityNotifier extends StateNotifier<LlmAvailability> {
  final Ref _ref;

  LlmAvailabilityNotifier(this._ref) : super(LlmAvailability.featureDisabled) {
    _check();
  }

  Future<void> _check() async {
    final enabled = _ref.read(aiFeatureEnabledProvider);
    if (!enabled) {
      state = LlmAvailability.featureDisabled;
      return;
    }

    final manager = _ref.read(modelManagerProvider);
    final ready = await manager.isModelReady();
    if (!ready) {
      state = LlmAvailability.modelNotDownloaded;
      return;
    }

    state = LlmAvailability.ready;
  }

  /// é‡æ–°æ£€æŸ¥å¯ç”¨æ€§çŠ¶æ€ã€‚
  Future<void> refresh() async {
    await _check();
  }

  /// åŠ è½½æ¨¡å‹åˆ°å†…å­˜ã€‚
  Future<void> loadModel() async {
    state = LlmAvailability.modelLoading;
    try {
      final manager = _ref.read(modelManagerProvider);
      final modelPath = await manager.getModelPath();
      if (modelPath == null) {
        state = LlmAvailability.modelNotDownloaded;
        return;
      }

      final llmService = _ref.read(llmServiceInstanceProvider);
      await llmService.loadModel(modelPath);
      state = LlmAvailability.ready;
    } catch (e) {
      state = LlmAvailability.error;
      rethrow;
    }
  }

  /// å¸è½½æ¨¡å‹ã€‚
  Future<void> unloadModel() async {
    final llmService = _ref.read(llmServiceInstanceProvider);
    await llmService.unloadModel();
    state = LlmAvailability.modelNotDownloaded;
  }

  void setError() => state = LlmAvailability.error;
  void setDisabled() => state = LlmAvailability.featureDisabled;
}

final llmAvailabilityProvider =
    StateNotifierProvider<LlmAvailabilityNotifier, LlmAvailability>(
  LlmAvailabilityNotifier.new,
);

// â”€â”€â”€ Model Download Progress â”€â”€â”€

/// æ¨¡å‹ä¸‹è½½è¿›åº¦çŠ¶æ€ã€‚
class ModelDownloadState {
  final bool isDownloading;
  final bool isPaused;
  final double progress; // 0.0 - 1.0
  final int downloadedBytes;
  final int totalBytes;
  final String? error;
  final DownloadTask? task;

  const ModelDownloadState({
    this.isDownloading = false,
    this.isPaused = false,
    this.progress = 0.0,
    this.downloadedBytes = 0,
    this.totalBytes = 0,
    this.error,
    this.task,
  });

  ModelDownloadState copyWith({
    bool? isDownloading,
    bool? isPaused,
    double? progress,
    int? downloadedBytes,
    int? totalBytes,
    String? error,
    DownloadTask? task,
  }) {
    return ModelDownloadState(
      isDownloading: isDownloading ?? this.isDownloading,
      isPaused: isPaused ?? this.isPaused,
      progress: progress ?? this.progress,
      downloadedBytes: downloadedBytes ?? this.downloadedBytes,
      totalBytes: totalBytes ?? this.totalBytes,
      error: error,
      task: task ?? this.task,
    );
  }
}

/// æ¨¡å‹ä¸‹è½½æ§åˆ¶å™¨ã€‚
class ModelDownloadNotifier extends StateNotifier<ModelDownloadState> {
  final Ref _ref;

  ModelDownloadNotifier(this._ref) : super(const ModelDownloadState());

  /// å¼€å§‹ä¸‹è½½æ¨¡å‹ã€‚
  Future<void> startDownload() async {
    if (state.isDownloading) return;

    final manager = _ref.read(modelManagerProvider);

    try {
      final task = await manager.startDownload();

      state = state.copyWith(
        isDownloading: true,
        isPaused: false,
        progress: 0.0,
        error: null,
        task: task,
      );

      // ç›‘å¬ä¸‹è½½è¿›åº¦
      FileDownloader().updates.listen((update) {
        if (!mounted) return;

        if (update is TaskStatusUpdate) {
          _handleStatusUpdate(update);
        } else if (update is TaskProgressUpdate) {
          _handleProgressUpdate(update);
        }
      });
    } catch (e) {
      state = state.copyWith(
        isDownloading: false,
        error: e.toString(),
      );
    }
  }

  void _handleStatusUpdate(TaskStatusUpdate update) {
    switch (update.status) {
      case TaskStatus.complete:
        _onDownloadComplete(update.task as DownloadTask);
      case TaskStatus.failed:
        state = state.copyWith(
          isDownloading: false,
          error: 'Download failed',
        );
      case TaskStatus.canceled:
        state = const ModelDownloadState();
      case TaskStatus.paused:
        state = state.copyWith(isPaused: true);
      case TaskStatus.running:
        state = state.copyWith(isPaused: false, isDownloading: true);
      default:
        break;
    }
  }

  void _handleProgressUpdate(TaskProgressUpdate update) {
    if (!mounted) return;
    final expectedSize = update.expectedFileSize;
    final downloaded = expectedSize > 0
        ? (update.progress * expectedSize).round()
        : 0;

    state = state.copyWith(
      progress: update.progress.clamp(0.0, 1.0),
      downloadedBytes: downloaded,
      totalBytes: expectedSize > 0 ? expectedSize : LlmConstants.modelFileSizeBytes,
    );
  }

  Future<void> _onDownloadComplete(DownloadTask task) async {
    final manager = _ref.read(modelManagerProvider);
    final filePath = await task.filePath();

    final verified = await manager.verifyAndSaveModel(filePath);
    if (verified) {
      state = state.copyWith(
        isDownloading: false,
        progress: 1.0,
      );
      // åˆ·æ–° LLM å¯ç”¨æ€§
      _ref.read(llmAvailabilityProvider.notifier).refresh();
    } else {
      state = state.copyWith(
        isDownloading: false,
        error: 'Model verification failed',
      );
    }
  }

  /// æš‚åœä¸‹è½½ã€‚
  Future<void> pause() async {
    final task = state.task;
    if (task == null) return;
    await _ref.read(modelManagerProvider).pauseDownload(task);
  }

  /// æ¢å¤ä¸‹è½½ã€‚
  Future<void> resume() async {
    final task = state.task;
    if (task == null) return;
    await _ref.read(modelManagerProvider).resumeDownload(task);
  }

  /// å–æ¶ˆä¸‹è½½ã€‚
  Future<void> cancel() async {
    final task = state.task;
    if (task == null) return;
    await _ref.read(modelManagerProvider).cancelDownload(task);
    state = const ModelDownloadState();
  }
}

final modelDownloadProvider =
    StateNotifierProvider<ModelDownloadNotifier, ModelDownloadState>(
  ModelDownloadNotifier.new,
);
